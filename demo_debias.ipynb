{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import CLIPModel, AutoProcessor\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import yaml\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "import queries\n",
    "import scipy.stats\n",
    "from bend_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.safe_load(open(\"experimental_configs/celeba_hair_gender_clip-vit-base-patch16.yml\"))\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_MODEL_NAME = config['model_ID'].split('/')[-1]\n",
    "_MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_to_debias = config['att_to_debias']\n",
    "dataset_name = config['dataset_name']\n",
    "model_ID = config['model_ID']\n",
    "query_type = config['query_type']\n",
    "random_seed = config['random_seed']\n",
    "\n",
    "if query_type == 'hair':\n",
    "    query_classes = queries.hair_classes\n",
    "\n",
    "elif query_type == 'stereotype':\n",
    "    query_classes = queries.stereotype_classes\n",
    "\n",
    "else:\n",
    "    print(f'{query_type} not implemented')\n",
    "\n",
    "print(f\"query_classes: {query_classes}\")\n",
    "\n",
    "#\n",
    "normalize = True\n",
    "lam = 1000\n",
    "#\n",
    "\n",
    "if att_to_debias == 'race':\n",
    "    if dataset_name == 'UTKFace':\n",
    "        att_elements = ['White', 'Black', 'Asian', 'Indian', 'Latino Hispanic']\n",
    "    else:\n",
    "        att_elements = ['Black', 'East Asian', 'Indian', 'Latino_Hispanic', 'Middle Eastern', 'Southeast Asian', 'White']\n",
    "elif att_to_debias == 'gender':\n",
    "    att_elements = ['Male', 'Female']\n",
    "else:\n",
    "    print('{att_to_debias} not implemented')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_id = config['model_ID']\n",
    "\n",
    "vl_model = CLIPModel.from_pretrained(model_ID).to(device)\n",
    "processor = AutoProcessor.from_pretrained(model_ID)\n",
    "\n",
    "def get_embeddings(input_text : list, clip_model, clip_processor, normalize=True):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = clip_processor(text=input_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        query_text_embedding = clip_model.get_text_features(**inputs)#.to('cpu').numpy()\n",
    "\n",
    "    if normalize:\n",
    "        query_text_embedding /= query_text_embedding.norm(dim=-1, keepdim=True)\n",
    "    return query_text_embedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utk_ethnicity_map(x):\n",
    "    if x == 0:\n",
    "        return 'White'\n",
    "    if x == 1:\n",
    "        return 'Black'\n",
    "    if x == 2:\n",
    "        return 'Asian'\n",
    "    if x == 3:\n",
    "        return 'Indian'\n",
    "    if x == 4:\n",
    "        return 'Latino Hispanic'\n",
    "\n",
    "\n",
    "\n",
    "def load_embedding_dataset(ds_path):\n",
    "    embeddings_dataset = load_dataset(\"json\", data_files=ds_path, split='train')\n",
    "    embeddings_dataset = embeddings_dataset.with_format(\"np\", columns=[\"embedding\"], output_all_columns=True)\n",
    "\n",
    "    if 'Male' in embeddings_dataset.features.keys():\n",
    "        embeddings_dataset = embeddings_dataset.map(\n",
    "            lambda x: {\"gender\": 'Male' if x['Male'] == 1 else 'Female'})\n",
    "    if 'utk_race' in embeddings_dataset.features.keys():\n",
    "        embeddings_dataset = embeddings_dataset.map(\n",
    "            lambda x: {\"race\": utk_ethnicity_map(x['utk_race'])})\n",
    "\n",
    "    if normalize:\n",
    "        embeddings_dataset = embeddings_dataset.map(\n",
    "            lambda x: {\"embedding\": x['embedding'].reshape(-1)/np.linalg.norm(x['embedding'].reshape(-1))})\n",
    "    else:\n",
    "        embeddings_dataset = embeddings_dataset.map(\n",
    "            lambda x: {\"embedding\": x['embedding'].reshape(-1)})\n",
    "    return embeddings_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_embeddings_dataset = load_embedding_dataset(f'data/{dataset_name}_featurized_{_MODEL_NAME}.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"query_templates/{query_type}_{att_to_debias}_query_templates.json\", 'r') as file:\n",
    "    instantiated_search_classes = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instantiated_search_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/fold_indices/{dataset_name}_featurized_{_MODEL_NAME}_folds.jsonl\", 'r') as file:\n",
    "    fold_dict = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_embeddings_dataset = _embeddings_dataset.select(fold_dict[str(0)]['train_indices'])\n",
    "target_embeddings_dataset = _embeddings_dataset.select(fold_dict[str(0)]['test_indices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if query_type == 'hair':\n",
    "    query_is_labeled = True\n",
    "else:\n",
    "    query_is_labeled = False\n",
    "\n",
    "ref_spurious_class_list = att_elements\n",
    "target_spurious_class_list = att_elements\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "result_dict = {}\n",
    "for query_class in query_classes:\n",
    "    result_dict[query_class] = {}\n",
    "\n",
    "    result_dict[query_class]['Vanilla'] = {}\n",
    "\n",
    "    result_dict[query_class]['P0'] = {}\n",
    "\n",
    "    result_dict[query_class]['Inclusive_P0'] = {}\n",
    "\n",
    "    result_dict[query_class]['bend_vlm'] = {}\n",
    "\n",
    "\n",
    "\n",
    "    for k_fold in range(5):\n",
    "\n",
    "        reference_embeddings_dataset = _embeddings_dataset.select(fold_dict[str(k_fold)]['train_indices'])\n",
    "        target_embeddings_dataset = _embeddings_dataset.select(fold_dict[str(k_fold)]['test_indices'])\n",
    "\n",
    "        query_text = [instantiated_search_classes[query_class]['query']]\n",
    "        print(query_class)\n",
    "        print(query_text)\n",
    "\n",
    "\n",
    "        spurious_prompt = instantiated_search_classes[query_class]['spurious_prompts']\n",
    "        inclusive_candidate_prompt = instantiated_search_classes[query_class]['augmentations']\n",
    "        S = [[0,1]]\n",
    "\n",
    "        print(spurious_prompt)\n",
    "        print(inclusive_candidate_prompt)\n",
    "\n",
    "        spurious_att_array = np.asarray(target_embeddings_dataset[att_to_debias])\n",
    "        ref_spurious_att_array = np.asarray(reference_embeddings_dataset[att_to_debias])\n",
    "\n",
    "        spurious_att_prior = {}\n",
    "        for spurious_att in target_spurious_class_list:\n",
    "            spurious_att_prior[spurious_att] = spurious_att_array[spurious_att_array==spurious_att].shape[0]/spurious_att_array.shape[0]\n",
    "        print(f'spurious att prior: {spurious_att_prior}')\n",
    "\n",
    "\n",
    "        ref_spurious_att_prior = {}\n",
    "        for r_spurious_att in ref_spurious_class_list:\n",
    "            ref_spurious_att_prior[r_spurious_att] = ref_spurious_att_array[ref_spurious_att_array==r_spurious_att].shape[0]/ref_spurious_att_array.shape[0]\n",
    "        print(f'ref spurious att prior: {ref_spurious_att_prior}')\n",
    "\n",
    "        if query_is_labeled:\n",
    "            eg_array = np.asarray(target_embeddings_dataset[query_class])\n",
    "            conditional_spurious_att_prior = {}\n",
    "            conditional_spurious_att_array = spurious_att_array[eg_array==1]\n",
    "            for spurious_att in target_spurious_class_list:\n",
    "                conditional_spurious_att_prior[spurious_att] = conditional_spurious_att_array[conditional_spurious_att_array==spurious_att].shape[0]/conditional_spurious_att_array.shape[0]\n",
    "            print(f'conditional spurious att prior: {conditional_spurious_att_prior}')\n",
    "\n",
    "        if query_is_labeled:\n",
    "            prior_for_metric =spurious_att_prior\n",
    "        else:\n",
    "            prior_for_metric = spurious_att_prior\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        query_text_embedding = get_embeddings(query_text, vl_model, processor, normalize).to('cpu').numpy()\n",
    "        spurious_prompt_embedding = get_embeddings(spurious_prompt, vl_model, processor, normalize).to('cpu').numpy()\n",
    "        inclusive_candidate_prompt_embedding = get_embeddings(inclusive_candidate_prompt, vl_model, processor, normalize).to('cpu').numpy()\n",
    "\n",
    "        P0 = get_proj_matrix(spurious_prompt_embedding)\n",
    "\n",
    "        M = get_M(inclusive_candidate_prompt_embedding, S)\n",
    "        G = lam * M + np.eye(M.shape[0])\n",
    "        inclusive_P_star = np.matmul(P0, np.linalg.inv(G))\n",
    "\n",
    "\n",
    "        P0_embeddings = np.matmul(query_text_embedding, P0.T)\n",
    "        P0_embeddings = F.normalize(torch.tensor(P0_embeddings), dim=-1).numpy()\n",
    "\n",
    "        inclusive_P_star_embeddings = np.matmul(query_text_embedding, inclusive_P_star.T)\n",
    "        inclusive_P_star_embeddings = F.normalize(torch.tensor(inclusive_P_star_embeddings), dim=-1).numpy()\n",
    "\n",
    "\n",
    "\n",
    "        rewrite_pair_list = []\n",
    "        for e_i in range(inclusive_candidate_prompt_embedding.shape[0]):\n",
    "            for e_j in range(e_i+1, inclusive_candidate_prompt_embedding.shape[0]):\n",
    "                rewrite_pair_list.append(((inclusive_candidate_prompt_embedding[e_i] - inclusive_candidate_prompt_embedding[e_j])/2).reshape(1,-1) )\n",
    "\n",
    "\n",
    "        sub_local_embeddings = np.concatenate(rewrite_pair_list)\n",
    "        print(sub_local_embeddings.shape)\n",
    "        sub_local_embeddings = np.concatenate([spurious_prompt_embedding, sub_local_embeddings])\n",
    "        P0_local = get_proj_matrix(sub_local_embeddings)\n",
    "        #\n",
    "        P0_local_embeddings = np.matmul(query_text_embedding, P0_local.T)\n",
    "        P0_local_embeddings = F.normalize(torch.tensor(P0_local_embeddings), dim=-1).numpy()\n",
    "\n",
    "\n",
    "        #######\n",
    "\n",
    "        if att_to_debias == 'gender':\n",
    "            num_neighbors = 100\n",
    "            K = 500\n",
    "        else: \n",
    "            num_neighbors = 10\n",
    "            K = 500\n",
    "        ref_dataset = reference_embeddings_dataset\n",
    "        spurious_class_list = ref_spurious_class_list\n",
    "        \n",
    "        target_dist = ref_spurious_att_prior\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        bend_vlm_embeddings, x_mean, y_means = legrange_text(query_text_embedding, reference_embeddings_dataset, spurious_label=att_to_debias, \n",
    "                                                spurious_class_list=att_elements, num_neighbors=num_neighbors, proj_matrix = P0_local, normalize=normalize)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        result_dict[query_class]['Vanilla'][f'fold_{k_fold}'] = get_metrics(query_text_embedding, query_class, att_to_debias, \n",
    "                                                K, prior_for_metric, target_spurious_class_list, name='Vanilla', target_dataset = target_embeddings_dataset,\n",
    "                                                QUERY_IS_LABELED=query_is_labeled)\n",
    "\n",
    "\n",
    "        result_dict[query_class]['P0'][f'fold_{k_fold}'] = get_metrics(P0_embeddings, query_class, att_to_debias, K, prior_for_metric, \n",
    "                                                        target_spurious_class_list, name='P0', target_dataset = target_embeddings_dataset, QUERY_IS_LABELED=query_is_labeled)\n",
    "\n",
    "        result_dict[query_class]['Inclusive_P0'][f'fold_{k_fold}'] = get_metrics(inclusive_P_star_embeddings, query_class, att_to_debias, K, prior_for_metric,\n",
    "                                                    target_spurious_class_list, name='Inclusive_P0', target_dataset = target_embeddings_dataset, QUERY_IS_LABELED=query_is_labeled)\n",
    "\n",
    "\n",
    "        print('***'*7)\n",
    "        print()\n",
    "        result_dict[query_class]['bend_vlm'][f'fold_{k_fold}'] = get_metrics(bend_vlm_embeddings, query_class, att_to_debias, K, prior_for_metric, \n",
    "                                                            target_spurious_class_list, name='bend_vlm', target_dataset = target_embeddings_dataset, \n",
    "                                                            QUERY_IS_LABELED=query_is_labeled)\n",
    "\n",
    "\n",
    "        print('--'*7)\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['Vanilla', 'P0', 'Inclusive_P0', 'bend_vlm']\n",
    "\n",
    "\n",
    "\n",
    "kl_mean = []\n",
    "kl_ci =[]\n",
    "\n",
    "max_skew_mean =[]\n",
    "max_skew_ci =[]\n",
    "\n",
    "#\n",
    "auc_mean =[]\n",
    "auc_ci =[]\n",
    "gap_mean =[]\n",
    "gap_ci =[]\n",
    "#\n",
    "\n",
    "for m in methods:\n",
    "    kl_avg_list = []\n",
    "    max_skew_avg_list = []\n",
    "\n",
    "    #\n",
    "    auc_avg_list = []\n",
    "    gap_avg_list = []\n",
    "    #\n",
    "\n",
    "    for fold in range(5):\n",
    "        kl_list = []\n",
    "        max_skew_list =[]\n",
    "\n",
    "        #\n",
    "        auc_list =[]\n",
    "        gap_list =[]\n",
    "        #\n",
    "\n",
    "        for att in result_dict.keys():\n",
    "            kl_list.append(result_dict[att][m][f\"fold_{fold}\"]['kl_prior'])\n",
    "            max_skew_list.append(result_dict[att][m][f\"fold_{fold}\"]['max_skew_prior'])\n",
    "\n",
    "            #\n",
    "            auc_list.append(result_dict[att][m][f\"fold_{fold}\"]['worst_auc_roc_val'])\n",
    "            gap_list.append(result_dict[att][m][f\"fold_{fold}\"]['auc_roc_gap'])\n",
    "            #\n",
    "\n",
    "        kl_avg_list.append(np.mean(kl_list))\n",
    "        max_skew_avg_list.append(np.mean(max_skew_list))\n",
    "\n",
    "        #\n",
    "        auc_avg_list.append(np.mean(auc_list))\n",
    "        gap_avg_list.append(np.mean(gap_list))\n",
    "        #\n",
    "\n",
    "    _m, _h = mean_confidence_interval(kl_avg_list)\n",
    "    kl_mean.append(_m)\n",
    "    kl_ci.append(_h)\n",
    "\n",
    "    _m, _h = mean_confidence_interval(max_skew_avg_list)\n",
    "    max_skew_mean.append(_m)\n",
    "    max_skew_ci.append(_h)\n",
    "\n",
    "    #\n",
    "    _m, _h = mean_confidence_interval(auc_avg_list)\n",
    "    auc_mean.append(_m)\n",
    "    auc_ci.append(_h)\n",
    "    _m, _h = mean_confidence_interval(gap_avg_list)\n",
    "    gap_mean.append(_m)\n",
    "    gap_ci.append(_h)\n",
    "    #\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'Method': methods, 'KL_Div': kl_mean, 'KL_CI': kl_ci, 'MaxSkew': max_skew_mean, \n",
    "                   'MaxSkew_CI': max_skew_ci,\n",
    "                   #\n",
    "                   'Worst_Group_Auc_Roc': auc_mean,\n",
    "                   'Worst_Group_Auc_Roc_CI': auc_ci,\n",
    "                   'Gap': gap_mean,\n",
    "                   'Gap_CI': gap_ci\n",
    "                   #\n",
    "                   })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "derm_diff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
